# reading_libs
- MAE（Masked Autoencoders Are Scalable Vision Learners）
来源：CVPR 2022 [link](libs/MAE.md)
- transformer（Attention Is All You Need）
来源：NIPS 2017 [link](libs/transformers.md)
- ViT(An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale) [link](libs/ViT.md)
- MVP 基于 MAE 为 encoder，PPO 为 agent 的 motor control 任务 [link](libs/MVP.md)