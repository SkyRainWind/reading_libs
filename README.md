# reading_libs
- MAE（Masked Autoencoders Are Scalable Vision Learners）
来源：CVPR 2022 [link](libs/MAE.md)
- transformer（Attention Is All You Need）
来源：NIPS 2017 [link](libs/transformers.md)
- ViT(An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale) [link](libs/ViT.md)
- MVP 基于 MAE 为 encoder，PPO 为 agent 的 motor control 任务 [link](libs/MVP.md)
- Maniwhere 基于对比学习（同一图片不同视角作为正样本）、不同视角 feature map 的相似度尽量小、STN 提供空间位置信息、SRM 和 random overlay 对模型进行 curriculum learning，实现由仿真直接应用到真实环境中的 zero-shot 模型 [link](libs/Maniwhere.md)